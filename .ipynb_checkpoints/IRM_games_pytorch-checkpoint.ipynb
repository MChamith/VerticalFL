{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c10ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "033a8313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random input size and classification classes\n",
    "length = 300\n",
    "width = 10\n",
    "\n",
    "num_classes = 5\n",
    "learning_rate    = 2.5e-4\n",
    "\n",
    "num_epochs       = 25\n",
    "batch_size       = 256\n",
    "termination_acc  = 0.6\n",
    "warm_start       = 100\n",
    "learning_rate    = 4e-4\n",
    "n_e = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39d4d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepresentationLearner(nn.Module):\n",
    "    def __init__(self, length, width):\n",
    "        super(RepresentationLearner, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(300 * 10, 390)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Define L2 regularization manually in PyTorch\n",
    "        self.l2_reg = nn.Parameter(torch.tensor(0.00125), requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print('x shape before flatten ' + str(x.shape))\n",
    "        x = self.flatten(x)\n",
    "#         print('x size ' + str(x.shape))\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "#         # Applying L2 regularization\n",
    "#         l2_penalty = torch.norm(self.fc1.weight) * self.l2_reg\n",
    "#         x = x + l2_penalty\n",
    "\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c49394a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Extractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Extractor, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(390, 390)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(390, 390)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(390, 5)\n",
    "\n",
    "#         # Define L2 regularization manually in PyTorch\n",
    "#         self.l2_reg = nn.Parameter(torch.tensor(0.00125), requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # Applying dropout and L2 regularization\n",
    "        x = self.dropout2(x)\n",
    "#         l2_penalty = torch.norm(self.fc2.weight) * self.l2_reg\n",
    "#         x = x + l2_penalty\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = Extractor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81df17a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_learner = RepresentationLearner(length, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccec9d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in rep_learner.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0caf7e46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1170390\n"
     ]
    }
   ],
   "source": [
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e6ffc094",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientUpdate(object):\n",
    "    def __init__(self,learning_rate):\n",
    "#         self.train_loader = DataLoader(CustomDataset(dataset, idxs), batch_size=batchSize, shuffle=True)\n",
    "        self.learning_rate = learning_rate\n",
    "       \n",
    "    def calculate_output(self, model, data):\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def get_loss(self, y, target):\n",
    "        loss_object = nn.CrossEntropyLoss()\n",
    "        loss = loss_object(y_, target)\n",
    "        \n",
    "        return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e95f4dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate random data\n",
    "a1 = np.random.normal(size = (1000,300,10)) #input environment 1\n",
    "b1 = np.expand_dims(np.random.randint(low=0, high=5, size=(1000)),1) #classes environment 1\n",
    "\n",
    "a2 = np.random.normal(size = (1000,300,10)) #input environment 2\n",
    "b2 = np.expand_dims(np.random.randint(low=0, high=5, size=(1000)),1) #classes environment 2\n",
    "\n",
    "# combined input\n",
    "data = [(a1,b1), (a2,b2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e891d920",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X.npy', a1)\n",
    "np.save('y.npy', b1)\n",
    "\n",
    "np.save('X2.npy', a2)\n",
    "np.save('y2.npy', b2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1903e74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in = torch.from_numpy(np.concatenate((a1,a2))).to(torch.float32) \n",
    "y_in = torch.from_numpy(np.concatenate((b1,b2))).type(torch.LongTensor)  \n",
    "\n",
    "np.save('X_in.npy', x_in)\n",
    "np.save('y_in.npy', y_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1b0bee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.append((np.concatenate((a1,a2)),np.concatenate((b1,b2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b54ef8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = data[0][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a1757370",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004\n",
      "accuracy at epoch 0 0.1975\n",
      "0.0004\n",
      "accuracy at epoch 0 0.20075\n",
      "0.0004\n",
      "accuracy at epoch 0 0.20075\n",
      "0.0004\n",
      "accuracy at epoch 0 0.20125\n",
      "0.0004\n",
      "accuracy at epoch 0 0.20525\n",
      "0.0004\n",
      "accuracy at epoch 0 0.21\n",
      "0.0004\n",
      "accuracy at epoch 0 0.20925\n",
      "0.0004\n",
      "accuracy at epoch 0 0.1995\n",
      "0.0004\n",
      "accuracy at epoch 1 0.211\n",
      "0.0004\n",
      "accuracy at epoch 1 0.208\n",
      "0.0004\n",
      "accuracy at epoch 1 0.21175\n",
      "0.0004\n",
      "accuracy at epoch 1 0.21\n",
      "0.0004\n",
      "accuracy at epoch 1 0.20875\n",
      "0.0004\n",
      "accuracy at epoch 1 0.223\n",
      "0.0004\n",
      "accuracy at epoch 1 0.21575\n",
      "0.0004\n",
      "accuracy at epoch 1 0.21775\n",
      "0.0004\n",
      "accuracy at epoch 2 0.2255\n",
      "0.0004\n",
      "accuracy at epoch 2 0.22\n",
      "0.0004\n",
      "accuracy at epoch 2 0.22875\n",
      "0.0004\n",
      "accuracy at epoch 2 0.2155\n",
      "0.0004\n",
      "accuracy at epoch 2 0.23175\n",
      "0.0004\n",
      "accuracy at epoch 2 0.22275\n",
      "0.0004\n",
      "accuracy at epoch 2 0.22725\n",
      "0.0004\n",
      "accuracy at epoch 2 0.21025\n",
      "0.0004\n",
      "accuracy at epoch 3 0.22125\n",
      "0.0004\n",
      "accuracy at epoch 3 0.22525\n",
      "0.0004\n",
      "accuracy at epoch 3 0.23775\n",
      "0.0004\n",
      "accuracy at epoch 3 0.23875\n",
      "0.0004\n",
      "accuracy at epoch 3 0.2375\n",
      "0.0004\n",
      "accuracy at epoch 3 0.23725\n",
      "0.0004\n",
      "accuracy at epoch 3 0.239\n",
      "0.0004\n",
      "accuracy at epoch 3 0.23275\n",
      "0.0004\n",
      "accuracy at epoch 4 0.2395\n",
      "0.0004\n",
      "accuracy at epoch 4 0.23475\n",
      "0.0004\n",
      "accuracy at epoch 4 0.23925\n",
      "0.0004\n",
      "accuracy at epoch 4 0.2485\n",
      "0.0004\n",
      "accuracy at epoch 4 0.242\n",
      "0.0004\n",
      "accuracy at epoch 4 0.24825\n",
      "0.0004\n",
      "accuracy at epoch 4 0.23425\n",
      "0.0004\n",
      "accuracy at epoch 4 0.25825\n",
      "0.0004\n",
      "accuracy at epoch 5 0.25725\n",
      "0.0004\n",
      "accuracy at epoch 5 0.2575\n",
      "0.0004\n",
      "accuracy at epoch 5 0.254\n",
      "0.0004\n",
      "accuracy at epoch 5 0.256\n",
      "0.0004\n",
      "accuracy at epoch 5 0.264\n",
      "0.0004\n",
      "accuracy at epoch 5 0.276\n",
      "0.0004\n",
      "accuracy at epoch 5 0.2745\n",
      "0.0004\n",
      "accuracy at epoch 5 0.282\n",
      "0.0004\n",
      "accuracy at epoch 6 0.27725\n",
      "0.0004\n",
      "accuracy at epoch 6 0.26525\n",
      "0.0004\n",
      "accuracy at epoch 6 0.28425\n",
      "0.0004\n",
      "accuracy at epoch 6 0.2795\n",
      "0.0004\n",
      "accuracy at epoch 6 0.2775\n",
      "0.0004\n",
      "accuracy at epoch 6 0.2965\n",
      "0.0004\n",
      "accuracy at epoch 6 0.29975\n",
      "0.0004\n",
      "accuracy at epoch 6 0.306\n",
      "0.0004\n",
      "accuracy at epoch 7 0.29675\n",
      "0.0004\n",
      "accuracy at epoch 7 0.3065\n",
      "0.0004\n",
      "accuracy at epoch 7 0.30225\n",
      "0.0004\n",
      "accuracy at epoch 7 0.3185\n",
      "0.0004\n",
      "accuracy at epoch 7 0.32325\n",
      "0.0004\n",
      "accuracy at epoch 7 0.3215\n",
      "0.0004\n",
      "accuracy at epoch 7 0.33825\n",
      "0.0004\n",
      "accuracy at epoch 7 0.3215\n",
      "0.0004\n",
      "accuracy at epoch 8 0.33425\n",
      "0.0004\n",
      "accuracy at epoch 8 0.33725\n",
      "0.0004\n",
      "accuracy at epoch 8 0.3465\n",
      "0.0004\n",
      "accuracy at epoch 8 0.3615\n",
      "0.0004\n",
      "accuracy at epoch 8 0.37025\n",
      "0.0004\n",
      "accuracy at epoch 8 0.374\n",
      "0.0004\n",
      "accuracy at epoch 8 0.37525\n",
      "0.0004\n",
      "accuracy at epoch 8 0.376\n",
      "0.0004\n",
      "accuracy at epoch 9 0.3915\n",
      "0.0004\n",
      "accuracy at epoch 9 0.39375\n",
      "0.0004\n",
      "accuracy at epoch 9 0.4065\n",
      "0.0004\n",
      "accuracy at epoch 9 0.414\n",
      "0.0004\n",
      "accuracy at epoch 9 0.416\n",
      "0.0004\n",
      "accuracy at epoch 9 0.41825\n",
      "0.0004\n",
      "accuracy at epoch 9 0.42375\n",
      "0.0004\n",
      "accuracy at epoch 9 0.4395\n",
      "0.0004\n",
      "accuracy at epoch 10 0.443\n",
      "0.0004\n",
      "accuracy at epoch 10 0.43975\n",
      "0.0004\n",
      "accuracy at epoch 10 0.45325\n",
      "0.0004\n",
      "accuracy at epoch 10 0.456\n",
      "0.0004\n",
      "accuracy at epoch 10 0.4715\n",
      "0.0004\n",
      "accuracy at epoch 10 0.471\n",
      "0.0004\n",
      "accuracy at epoch 10 0.4775\n",
      "0.0004\n",
      "accuracy at epoch 10 0.484\n",
      "0.0004\n",
      "accuracy at epoch 11 0.48775\n",
      "0.0004\n",
      "accuracy at epoch 11 0.482\n",
      "0.0004\n",
      "accuracy at epoch 11 0.503\n",
      "0.0004\n",
      "accuracy at epoch 11 0.4985\n",
      "0.0004\n",
      "accuracy at epoch 11 0.51125\n",
      "0.0004\n",
      "accuracy at epoch 11 0.52275\n",
      "0.0004\n",
      "accuracy at epoch 11 0.533\n",
      "0.0004\n",
      "accuracy at epoch 11 0.52375\n",
      "0.0004\n",
      "accuracy at epoch 12 0.53675\n",
      "0.0004\n",
      "accuracy at epoch 12 0.53875\n",
      "0.0004\n",
      "accuracy at epoch 12 0.541\n",
      "0.0004\n",
      "accuracy at epoch 12 0.54975\n",
      "0.0004\n",
      "accuracy at epoch 12 0.54825\n",
      "0.0004\n",
      "accuracy at epoch 12 0.55225\n",
      "0.0004\n",
      "accuracy at epoch 12 0.55925\n",
      "0.0004\n",
      "accuracy at epoch 12 0.55875\n",
      "0.0004\n",
      "accuracy at epoch 13 0.56125\n",
      "0.0004\n",
      "accuracy at epoch 13 0.56425\n",
      "0.0004\n",
      "accuracy at epoch 13 0.5685\n",
      "0.0004\n",
      "accuracy at epoch 13 0.567\n",
      "0.0004\n",
      "accuracy at epoch 13 0.57\n",
      "0.0004\n",
      "accuracy at epoch 13 0.57\n",
      "0.0004\n",
      "accuracy at epoch 13 0.579\n",
      "0.0004\n",
      "accuracy at epoch 13 0.579\n",
      "0.0004\n",
      "accuracy at epoch 14 0.587\n",
      "0.0004\n",
      "accuracy at epoch 14 0.572\n",
      "0.0004\n",
      "accuracy at epoch 14 0.586\n",
      "0.0004\n",
      "accuracy at epoch 14 0.589\n",
      "0.0004\n",
      "accuracy at epoch 14 0.58625\n",
      "0.0004\n",
      "accuracy at epoch 14 0.59625\n",
      "0.0004\n",
      "accuracy at epoch 14 0.59125\n",
      "0.0004\n",
      "accuracy at epoch 14 0.587\n",
      "0.0004\n",
      "accuracy at epoch 15 0.59725\n",
      "0.0004\n",
      "accuracy at epoch 15 0.5935\n",
      "0.0004\n",
      "accuracy at epoch 15 0.6055\n",
      "0.0004\n",
      "accuracy at epoch 15 0.59425\n",
      "0.0004\n",
      "accuracy at epoch 15 0.5945\n",
      "0.0004\n",
      "accuracy at epoch 15 0.60425\n",
      "0.0004\n",
      "accuracy at epoch 15 0.59075\n",
      "0.0004\n",
      "accuracy at epoch 15 0.6025\n",
      "0.0004\n",
      "accuracy at epoch 16 0.6005\n",
      "0.0004\n",
      "accuracy at epoch 16 0.59675\n",
      "0.0004\n",
      "accuracy at epoch 16 0.605\n",
      "0.0004\n",
      "accuracy at epoch 16 0.60225\n",
      "0.0004\n",
      "accuracy at epoch 16 0.59925\n",
      "0.0004\n",
      "accuracy at epoch 16 0.6035\n",
      "0.0004\n",
      "accuracy at epoch 16 0.6065\n",
      "0.0004\n",
      "accuracy at epoch 16 0.60025\n",
      "0.0004\n",
      "accuracy at epoch 17 0.601\n",
      "0.0004\n",
      "accuracy at epoch 17 0.608\n",
      "0.0004\n",
      "accuracy at epoch 17 0.601\n",
      "0.0004\n",
      "accuracy at epoch 17 0.6015\n",
      "0.0004\n",
      "accuracy at epoch 17 0.59575\n",
      "0.0004\n",
      "accuracy at epoch 17 0.60625\n",
      "0.0004\n",
      "accuracy at epoch 17 0.59675\n",
      "0.0004\n",
      "accuracy at epoch 17 0.60875\n",
      "0.0004\n",
      "accuracy at epoch 18 0.605\n",
      "0.0004\n",
      "accuracy at epoch 18 0.603\n",
      "0.0004\n",
      "accuracy at epoch 18 0.604\n",
      "0.0004\n",
      "accuracy at epoch 18 0.60525\n",
      "0.0004\n",
      "accuracy at epoch 18 0.6005\n",
      "0.0004\n",
      "accuracy at epoch 18 0.602\n",
      "0.0004\n",
      "accuracy at epoch 18 0.60375\n",
      "0.0004\n",
      "accuracy at epoch 18 0.60525\n",
      "0.0004\n",
      "accuracy at epoch 19 0.609\n",
      "0.0004\n",
      "accuracy at epoch 19 0.60775\n",
      "0.0004\n",
      "accuracy at epoch 19 0.60575\n",
      "0.0004\n",
      "accuracy at epoch 19 0.60925\n",
      "0.0004\n",
      "accuracy at epoch 19 0.60775\n",
      "0.0004\n",
      "accuracy at epoch 19 0.60575\n",
      "0.0004\n",
      "accuracy at epoch 19 0.60075\n",
      "0.0004\n",
      "accuracy at epoch 19 0.605\n",
      "0.0004\n",
      "accuracy at epoch 20 0.61125\n",
      "0.0004\n",
      "accuracy at epoch 20 0.60425\n",
      "0.0004\n",
      "accuracy at epoch 20 0.605\n",
      "0.0004\n",
      "accuracy at epoch 20 0.6045\n",
      "0.0004\n",
      "accuracy at epoch 20 0.60775\n",
      "0.0004\n",
      "accuracy at epoch 20 0.6055\n",
      "0.0004\n",
      "accuracy at epoch 20 0.6055\n",
      "0.0004\n",
      "accuracy at epoch 20 0.60925\n",
      "0.0004\n",
      "accuracy at epoch 21 0.60275\n",
      "0.0004\n",
      "accuracy at epoch 21 0.6075\n",
      "0.0004\n",
      "accuracy at epoch 21 0.6095\n",
      "0.0004\n",
      "accuracy at epoch 21 0.6035\n",
      "0.0004\n",
      "accuracy at epoch 21 0.605\n",
      "0.0004\n",
      "accuracy at epoch 21 0.60625\n",
      "0.0004\n",
      "accuracy at epoch 21 0.60725\n",
      "0.0004\n",
      "accuracy at epoch 21 0.606\n",
      "0.0004\n",
      "accuracy at epoch 22 0.60375\n",
      "0.0004\n",
      "accuracy at epoch 22 0.604\n",
      "0.0004\n",
      "accuracy at epoch 22 0.61\n",
      "0.0004\n",
      "accuracy at epoch 22 0.60775\n",
      "0.0004\n",
      "accuracy at epoch 22 0.60475\n",
      "0.0004\n",
      "accuracy at epoch 22 0.604\n",
      "0.0004\n",
      "accuracy at epoch 22 0.61075\n",
      "0.0004\n",
      "accuracy at epoch 22 0.60275\n",
      "0.0004\n",
      "accuracy at epoch 23 0.61025\n",
      "0.0004\n",
      "accuracy at epoch 23 0.6075\n",
      "0.0004\n",
      "accuracy at epoch 23 0.60225\n",
      "0.0004\n",
      "accuracy at epoch 23 0.60025\n",
      "0.0004\n",
      "accuracy at epoch 23 0.607\n",
      "0.0004\n",
      "accuracy at epoch 23 0.605\n",
      "0.0004\n",
      "accuracy at epoch 23 0.604\n",
      "0.0004\n",
      "accuracy at epoch 23 0.602\n",
      "0.0004\n",
      "accuracy at epoch 24 0.6095\n",
      "0.0004\n",
      "accuracy at epoch 24 0.60975\n",
      "0.0004\n",
      "accuracy at epoch 24 0.60625\n",
      "0.0004\n",
      "accuracy at epoch 24 0.60825\n",
      "0.0004\n",
      "accuracy at epoch 24 0.6065\n",
      "0.0004\n",
      "accuracy at epoch 24 0.60625\n",
      "0.0004\n",
      "accuracy at epoch 24 0.6075\n",
      "0.0004\n",
      "accuracy at epoch 24 0.6035\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_list = []\n",
    "rep_model = RepresentationLearner(length, width) \n",
    "model_list.append(rep_model)\n",
    "local_update = ClientUpdate(learning_rate)\n",
    "loss_object = nn.CrossEntropyLoss()\n",
    "for i in range(n_e):\n",
    "    extractor = Extractor(num_classes)\n",
    "    model_list.append(extractor)\n",
    "    \n",
    "\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    count = 0\n",
    "    for offset in range(0,num_examples, batch_size):\n",
    "        end = offset + batch_size\n",
    "        curr_model =  2 - (count % 3)\n",
    "        outputs = []\n",
    "        losses = []\n",
    "        y_t= torch.from_numpy(data[0][1]).type(torch.LongTensor) \n",
    "\n",
    "        y_ = torch.zeros_like(y_t, dtype=torch.float32)\n",
    "#         print('y_ shape1 ' + str(y_.shape))\n",
    "        outputs = []\n",
    "        targets = []\n",
    "        y_s = []\n",
    "        for model_idx in range(2):\n",
    "           \n",
    "            input_x = torch.from_numpy(data[model_idx][0][offset:end,:]).to(torch.float32)\n",
    "            input_x.requires_grad = True\n",
    "#             print(np.squeeze(data[model_idx][1]).shape)\n",
    "            outpu_y =  torch.from_numpy(data[model_idx][1][offset:end,:]).type(torch.float32) \n",
    "             \n",
    "            z = model_list[0](input_x)\n",
    "#             z = pickle.loads(pickle.dumps(z))\n",
    "         \n",
    "#             print('z ' +str(z))\n",
    "#             print('y_ ' + str(y_.shape))\n",
    "            y_o1 = local_update.calculate_output(model_list[1], z)\n",
    "#             y_o1 = pickle.loads(pickle.dumps(y_o1))\n",
    "            \n",
    "               \n",
    "            y_o2 = local_update.calculate_output(model_list[2], z)\n",
    "#             y_o2 = pickle.loads(pickle.dumps(y_o2))\n",
    "          \n",
    "            \n",
    "            y_o = 0.5*y_o1 + 0.5*y_o2\n",
    "            outputs.append(y_o)\n",
    "            targets.append(outpu_y)\n",
    "        \n",
    "        z_rep = model_list[0](x_in[offset:end,:])\n",
    "#         print('zres ' + str(z_rep))\n",
    "        y_o1 = local_update.calculate_output(model_list[1], z_rep)\n",
    "#         y_o1 = pickle.loads(pickle.dumps(y_o1))\n",
    "        \n",
    "        y_o2 = local_update.calculate_output(model_list[2], z_rep)\n",
    "#         y_o2 = pickle.loads(pickle.dumps(y_o2))\n",
    "      \n",
    "        \n",
    "        rep_out = 0.5*y_o1 + 0.5*y_o2\n",
    "        \n",
    "        outputs.append(rep_out)\n",
    "        \n",
    "        \n",
    "        \n",
    "        for o_idx in range(len(outputs)):\n",
    "            \n",
    "            target =  torch.from_numpy(data[o_idx][1][offset:end,:]).type(torch.LongTensor) \n",
    "            \n",
    "            y = outputs[o_idx]\n",
    "            \n",
    "#             print('y ' + str(y))\n",
    "            loss_object = nn.CrossEntropyLoss()\n",
    "            loss = loss_object(y, torch.squeeze(target))\n",
    "#             print(loss)\n",
    "            losses.append(loss)\n",
    "        \n",
    "        model_list[curr_model].train()\n",
    "#         print('model  ' + str(model_list[curr_model].state_dict()))\n",
    "        if curr_model == 0:\n",
    "            optimizer = torch.optim.Adam(model_list[curr_model].parameters(), lr=learning_rate)\n",
    "          \n",
    "        else:\n",
    "            optimizer = torch.optim.Adam(model_list[curr_model].parameters(), lr=learning_rate)\n",
    "#         optimizer.zero_grad()\n",
    "#         print(losses[curr_model])\n",
    "        losses[curr_model].backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "#         print(list(model_list[curr_model].parameters())[0].grad)\n",
    "        #         y_ = torch.zeros_like(y_in, dtype=torch.float32)\n",
    "        \n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(param_group['lr'])\n",
    "        yout = 0\n",
    "        z = model_list[0](x_in)\n",
    "        for e in range(2):\n",
    "            yout += model_list[e+1](z)\n",
    "#             print('yout shape ' + str(yout.shape))\n",
    "#         print(model_list[0].state_dict())\n",
    "        # Calculate accuracy using PyTorch\n",
    "        criterion = nn.CrossEntropyLoss()  # Assuming you are calculating accuracy using cross-entropy loss\n",
    "        predictions = yout.argmax(dim=1)  # Assuming y_ contains raw logits\n",
    "#         print(predictions.eq(y_in.data.view_as(predictions)).sum().item()/ len(y_in))\n",
    "        accuracy = predictions.eq(y_in.data.view_as(predictions)).sum().item()/ len(y_in)\n",
    "        print('accuracy at epoch ' + str(i) +' ' + str(accuracy))\n",
    "        \n",
    "#         rep_loss = \n",
    "            \n",
    "#         print(model_list[curr_model])\n",
    "            \n",
    "\n",
    "#         loss = loss_object(y_, torch.squeeze(outpu_y))\n",
    "#         print('current model ' + str(curr_model))\n",
    "#         model_list[curr_model].train()        \n",
    "#         optimizer = torch.optim.Adam(model_list[curr_model].parameters(), lr=learning_rate)\n",
    "#         loss.backward() \n",
    "#         optimizer.step()\n",
    "        \n",
    "# #         y_ = torch.zeros_like(y_in, dtype=torch.float32)\n",
    "#         yout = 0\n",
    "#         z = model_list[0](x_in)\n",
    "#         for e in range(2):\n",
    "#             yout += model_list[e+1](z)\n",
    "# #             print('yout shape ' + str(yout.shape))\n",
    "\n",
    "#         # Calculate accuracy using PyTorch\n",
    "#         criterion = nn.CrossEntropyLoss()  # Assuming you are calculating accuracy using cross-entropy loss\n",
    "#         predictions = yout.argmax(dim=1)  # Assuming y_ contains raw logits\n",
    "# #         print(predictions.eq(y_in.data.view_as(predictions)).sum().item()/ len(y_in))\n",
    "#         accuracy = predictions.eq(y_in.data.view_as(predictions)).sum().item()/ len(y_in)\n",
    "#         print('accuracy ' + str(accuracy))\n",
    "        count +=1\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b03b4f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((1000,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085632db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
